{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'grading'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2aa05f1302ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"..\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgrading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'grading'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lfw_dataset\n",
      "\u001b[31m  Could not find a version that satisfies the requirement lfw_dataset (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for lfw_dataset\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install lfw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lfw_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2bd429c98deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlfw_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_lfw_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lfw_dataset'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras, keras.layers as L, keras.backend as K\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lfw_dataset import load_lfw_dataset\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import download_utils\n",
    "import keras_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! remember to clear session/graph if you rebuild your graph to avoid out-of-memory errors !!!\n",
    "def reset_tf_session():\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()\n",
    "    s = K.get_session()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset\n",
    "Dataset was downloaded for you. Relevant links (just in case): \n",
    "- http://www.cs.columbia.edu/CAVE/databases/pubfig/download/lfw_attributes.txt \n",
    "- http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz \n",
    "- http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
    "\n",
    "https://www.twblogs.net/a/5b8aeb992b71775d1ce9d07d/zh-cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we downloaded them for you, just link them here\n",
    "download_utils.link_week_4_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, attr = load_lfw_dataset(use_raw=True, dimx=32, dimy=32)\n",
    "IMG_SHAPE = X.shape[1:]\n",
    "\n",
    "# center images\n",
    "X = X.astype('float32') / 255.0 - 0.5\n",
    "\n",
    "# split\n",
    "X_train, X_test = train_test_split(X, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(x):\n",
    "    plt.imshow(np.clip(x + 0.5, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('sample images')\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    show_image(X[i])\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"attr shape:\", attr.shape)\n",
    "\n",
    "# try to free memory\n",
    "del X\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pca_autoencoder(img_shape, code_size):\n",
    "    \"\"\"\n",
    "    Here we define a simple linear autoencoder as described above.\n",
    "    We also flatten and un-flatten data to be compatible with image shapes\n",
    "    \"\"\"\n",
    "\n",
    "    encoder = keras.models.Sequential()\n",
    "    encoder.add(L.InputLayer(img_shape))\n",
    "    encoder.add(L.Flatten())                  #flatten image to vector\n",
    "    encoder.add(L.Dense(code_size))           #actual encoder\n",
    "\n",
    "    decoder = keras.models.Sequential()\n",
    "    decoder.add(L.InputLayer((code_size,)))\n",
    "    decoder.add(L.Dense(np.prod(img_shape)))  #actual decoder, height*width*3 units\n",
    "    decoder.add(L.Reshape(img_shape))         #un-flatten\n",
    "\n",
    "    return encoder,decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = reset_tf_session()\n",
    "\n",
    "encoder, decoder = build_pca_autoencoder(IMG_SHAPE, code_size=32)\n",
    "\n",
    "inp = L.Input(IMG_SHAPE)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = keras.models.Model(inputs=inp, outputs=reconstruction)\n",
    "autoencoder.compile(optimizer='adamax', loss='mse')\n",
    "\n",
    "autoencoder.fit(x=X_train, y=X_train, epochs=15,\n",
    "                validation_data=[X_test, X_test],\n",
    "                callbacks=[keras_utils.TqdmProgressCallback()],\n",
    "                verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(img,encoder,decoder):\n",
    "    \"\"\"Draws original, encoded and decoded images\"\"\"\n",
    "    code = encoder.predict(img[None])[0]  # img[None] is the same as img[np.newaxis, :]\n",
    "    reco = decoder.predict(code[None])[0]\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Original\")\n",
    "    show_image(img)\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Code\")\n",
    "    plt.imshow(code.reshape([code.shape[-1]//2,-1]))\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Reconstructed\")\n",
    "    show_image(reco)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = autoencoder.evaluate(X_test,X_test,verbose=0)\n",
    "print(\"PCA MSE:\", score)\n",
    "\n",
    "for i in range(5):\n",
    "    img = X_test[i]\n",
    "    visualize(img,encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.Conv2DTranspose(filters=?, kernel_size=(3, 3), strides=2, activation='relu', padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's play around with transpose convolution on examples first\n",
    "def test_conv2d_transpose(img_size, filter_size):\n",
    "    print(\"Transpose convolution test for img_size={}, filter_size={}:\".format(img_size, filter_size))\n",
    "\n",
    "    x = (np.arange(img_size ** 2, dtype=np.float32) + 1).reshape((1, img_size, img_size, 1))\n",
    "    f = (np.ones(filter_size ** 2, dtype=np.float32)).reshape((filter_size, filter_size, 1, 1))\n",
    "\n",
    "    conv = tf.nn.conv2d_transpose(x, f, \n",
    "                                  output_shape=(1, img_size * 2, img_size * 2, 1), \n",
    "                                  strides=[1, 2, 2, 1], \n",
    "                                  padding='SAME')\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        result = session.run(conv)\n",
    "        print(\"input:\")\n",
    "        print(x[0, :, :, 0])\n",
    "        print(\"filter:\")\n",
    "        print(f[:, :, 0, 0])\n",
    "        print(\"output:\")\n",
    "        print(result[0, :, :, 0])\n",
    "\n",
    "test_conv2d_transpose(img_size=2, filter_size=2)\n",
    "test_conv2d_transpose(img_size=2, filter_size=3)\n",
    "test_conv2d_transpose(img_size=4, filter_size=2)\n",
    "test_conv2d_transpose(img_size=4, filter_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep_autoencoder(img_shape, code_size):\n",
    "    \"\"\"PCA's deeper brother. See instructions above. Use `code_size` in layer definitions.\"\"\"\n",
    "    H,W,C = img_shape\n",
    "\n",
    "     # encoder\n",
    "    encoder = keras.models.Sequential()\n",
    "    encoder.add(L.InputLayer(img_shape))\n",
    "\n",
    "    # first conv layer\n",
    "    encoder.add(L.Conv2D(32, (3,3),strides = (1,1), activation='relu',padding = \"same\",  input_shape=(32, 32, 3)))\n",
    "    encoder.add(L.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "    #encoder.add(L.LeakyReLU(0.1))\n",
    "\n",
    "    # second conv layer\n",
    "    encoder.add(L.Conv2D(64, (3,3),strides = (1,1), activation='relu',padding = \"same\" ))\n",
    "    encoder.add(L.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "    #encoder.add(L.LeakyReLU(0.1))\n",
    "\n",
    "    # first pooling layer\n",
    "    #encoder.add(L.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "    #encoder.add(L.Dropout(0.25))\n",
    "\n",
    "    # third conv layer\n",
    "    encoder.add(L.Conv2D(128, (3,3),strides = (1,1), activation='relu',padding = \"same\"))\n",
    "    encoder.add(L.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "    #encoder.add(L.LeakyReLU(0.1))\n",
    "\n",
    "    # fourth conv layer\n",
    "    encoder.add(L.Conv2D(256, (3,3),strides = (1,1), activation='relu',padding = \"same\"))\n",
    "    encoder.add(L.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "    #encoder.add(L.LeakyReLU(0.1))\n",
    "\n",
    "    # second pooling layer\n",
    "    #encoder.add(L.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "    #encoder.add(L.Dropout(0.25))\n",
    "\n",
    "    encoder.add(L.Flatten())                  #flatten image to vector\n",
    "    encoder.add(L.Dense(code_size))           #actual encoder\n",
    "    ### YOUR CODE HERE: define encoder as per instructions above ###\n",
    "\n",
    "    # decoder\n",
    "    decoder = keras.models.Sequential()\n",
    "    decoder.add(L.InputLayer((code_size,)))\n",
    "    decoder.add(L.Dense(1024))  #actual decoder, height*width*3 units\n",
    "    decoder.add(L.Reshape((2,2,256)))\n",
    "    decoder.add(L.Conv2DTranspose(filters = 128, kernel_size=(3, 3), strides=2, activation='relu', padding='same'))\n",
    "    decoder.add(L.Conv2DTranspose(filters = 64, kernel_size=(3, 3), strides=2, activation='relu', padding='same'))\n",
    "    decoder.add(L.Conv2DTranspose(filters = 32, kernel_size=(3, 3), strides=2, activation='relu', padding='same'))\n",
    "    decoder.add(L.Conv2DTranspose(filters = 3, kernel_size=(3, 3), strides=2, activation= None, padding='same'))\n",
    "\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check autoencoder shapes along different code_sizes\n",
    "get_dim = lambda layer: np.prod(layer.output_shape[1:])\n",
    "for code_size in [1,8,32,128,512]:\n",
    "    s = reset_tf_session()\n",
    "    encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=code_size)\n",
    "    print(\"Testing code size %i\" % code_size)\n",
    "    assert encoder.output_shape[1:]==(code_size,),\"encoder must output a code of required size\"\n",
    "    assert decoder.output_shape[1:]==IMG_SHAPE,   \"decoder must output an image of valid shape\"\n",
    "    assert len(encoder.trainable_weights)>=6,     \"encoder must contain at least 3 layers\"\n",
    "    assert len(decoder.trainable_weights)>=6,     \"decoder must contain at least 3 layers\"\n",
    "\n",
    "    for layer in encoder.layers + decoder.layers:\n",
    "        assert get_dim(layer) >= code_size, \"Encoder layer %s is smaller than bottleneck (%i units)\"%(layer.name,get_dim(layer))\n",
    "\n",
    "print(\"All tests passed!\")\n",
    "s = reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at encoder and decoder shapes.\n",
    "# Total number of trainable parameters of encoder and decoder should be close.\n",
    "s = reset_tf_session()\n",
    "encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=32)\n",
    "encoder.summary()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = reset_tf_session()\n",
    "\n",
    "encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=32)\n",
    "\n",
    "inp = L.Input(IMG_SHAPE)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = keras.models.Model(inputs=inp, outputs=reconstruction)\n",
    "autoencoder.compile(optimizer=\"adamax\", loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will save model checkpoints here to continue training in case of kernel death\n",
    "model_filename = 'autoencoder.{0:03d}.hdf5'\n",
    "last_finished_epoch = None\n",
    "\n",
    "#### uncomment below to continue training from model checkpoint\n",
    "#### fill `last_finished_epoch` with your latest finished epoch\n",
    "# from keras.models import load_model\n",
    "# s = reset_tf_session()\n",
    "# last_finished_epoch = 4\n",
    "# autoencoder = load_model(model_filename.format(last_finished_epoch))\n",
    "# encoder = autoencoder.layers[1]\n",
    "# decoder = autoencoder.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x=X_train, y=X_train, epochs=25,\n",
    "                validation_data=[X_test, X_test],\n",
    "                callbacks=[keras_utils.ModelSaveCallback(model_filename),\n",
    "                           keras_utils.TqdmProgressCallback()],\n",
    "                verbose=0,\n",
    "                initial_epoch=last_finished_epoch or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_mse = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "print(\"Convolutional autoencoder MSE:\", reconstruction_mse)\n",
    "for i in range(5):\n",
    "    img = X_test[i]\n",
    "    visualize(img,encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained weights\n",
    "encoder.save_weights(\"encoder.h5\")\n",
    "decoder.save_weights(\"decoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore trained weights\n",
    "s = reset_tf_session()\n",
    "\n",
    "encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=32)\n",
    "encoder.load_weights(\"encoder.h5\")\n",
    "decoder.load_weights(\"decoder.h5\")\n",
    "\n",
    "inp = L.Input(IMG_SHAPE)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = keras.models.Model(inputs=inp, outputs=reconstruction)\n",
    "autoencoder.compile(optimizer=\"adamax\", loss='mse')\n",
    "\n",
    "print(autoencoder.evaluate(X_test, X_test, verbose=0))\n",
    "print(reconstruction_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gaussian_noise(X,sigma=0.1):\n",
    "    \"\"\"\n",
    "    adds noise from standard normal distribution with standard deviation sigma\n",
    "    :param X: image tensor of shape [batch,height,width,3]\n",
    "    Returns X + noise.\n",
    "    \"\"\"\n",
    "    noise = np.random.normal(loc=0.0, scale=sigma, size=X.shape)\n",
    "    return X + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise tests\n",
    "theoretical_std = (X_train[:100].std()**2 + 0.5**2)**.5\n",
    "our_std = apply_gaussian_noise(X_train[:100],sigma=0.5).std()\n",
    "assert abs(theoretical_std - our_std) < 0.01, \"Standard deviation does not match it's required value. Make sure you use sigma as std.\"\n",
    "assert abs(apply_gaussian_noise(X_train[:100],sigma=0.5).mean() - X_train[:100].mean()) < 0.01, \"Mean has changed. Please add zero-mean noise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different noise scales\n",
    "plt.subplot(1,4,1)\n",
    "show_image(X_train[0])\n",
    "plt.subplot(1,4,2)\n",
    "show_image(apply_gaussian_noise(X_train[:1],sigma=0.01)[0])\n",
    "plt.subplot(1,4,3)\n",
    "show_image(apply_gaussian_noise(X_train[:1],sigma=0.1)[0])\n",
    "plt.subplot(1,4,4)\n",
    "show_image(apply_gaussian_noise(X_train[:1],sigma=0.5)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = reset_tf_session()\n",
    "\n",
    "# we use bigger code size here for better quality\n",
    "encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=512)\n",
    "assert encoder.output_shape[1:]==(512,), \"encoder must output a code of required size\"\n",
    "\n",
    "inp = L.Input(IMG_SHAPE)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = keras.models.Model(inp, reconstruction)\n",
    "autoencoder.compile('adamax', 'mse')\n",
    "\n",
    "for i in range(25):\n",
    "    print(\"Epoch %i/25, Generating corrupted samples...\"%(i+1))\n",
    "    X_train_noise = apply_gaussian_noise(X_train)\n",
    "    X_test_noise = apply_gaussian_noise(X_test)\n",
    "\n",
    "    # we continue to train our model with new noise-augmented data\n",
    "    autoencoder.fit(x=X_train_noise, y=X_train, epochs=1,\n",
    "                    validation_data=[X_test_noise, X_test],\n",
    "                    callbacks=[keras_utils.TqdmProgressCallback()],\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noise = apply_gaussian_noise(X_test)\n",
    "denoising_mse = autoencoder.evaluate(X_test_noise, X_test, verbose=0)\n",
    "print(\"Denoising MSE:\", denoising_mse)\n",
    "for i in range(5):\n",
    "    img = X_test_noise[i]\n",
    "    visualize(img,encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore trained encoder weights\n",
    "s = reset_tf_session()\n",
    "encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=32)\n",
    "encoder.load_weights(\"encoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = X_train\n",
    "codes =  np.zeros([len(images),32])\n",
    "assert len(codes) == len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors.unsupervised import NearestNeighbors\n",
    "nei_clf = NearestNeighbors(metric=\"euclidean\")\n",
    "nei_clf.fit(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NearestNeighbors(algorithm='auto', leaf_size=30, metric='euclidean',\n",
    "         metric_params=None, n_jobs=1, n_neighbors=5, p=2, radius=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar(image, n_neighbors=5):\n",
    "    assert image.ndim==3,\"image must be [batch,height,width,3]\"\n",
    "\n",
    "    code = encoder.predict(image[None])\n",
    "\n",
    "    (distances,),(idx,) = nei_clf.kneighbors(code,n_neighbors=n_neighbors)\n",
    "\n",
    "    return distances,images[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similar(image):\n",
    "\n",
    "    distances,neighbors = get_similar(image,n_neighbors=3)\n",
    "\n",
    "    plt.figure(figsize=[8,7])\n",
    "    plt.subplot(1,4,1)\n",
    "    show_image(image)\n",
    "    plt.title(\"Original image\")\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1,4,i+2)\n",
    "        show_image(neighbors[i])\n",
    "        plt.title(\"Dist=%.3f\"%distances[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smiles\n",
    "show_similar(X_test[247])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ethnicity\n",
    "show_similar(X_test[56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " glasses\n",
    "show_similar(X_test[63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore trained encoder weights\n",
    "s = reset_tf_session()\n",
    "encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=32)\n",
    "encoder.load_weights(\"encoder.h5\")\n",
    "decoder.load_weights(\"decoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    image1,image2 = X_test[np.random.randint(0,len(X_test),size=2)]\n",
    "\n",
    "    code1, code2 = encoder.predict(np.stack([image1, image2]))\n",
    "\n",
    "    plt.figure(figsize=[10,4])\n",
    "    for i,a in enumerate(np.linspace(0,1,num=7)):\n",
    "\n",
    "        output_code = code1*(1-a) + code2*(a)\n",
    "        output_image = decoder.predict(output_code[None])[0]\n",
    "\n",
    "        plt.subplot(1,7,i+1)\n",
    "        show_image(output_image)\n",
    "        plt.title(\"a=%.2f\"%a)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
